{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ee9d64",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "\n",
    "# -> a concept in ML that models the relation between dependent and independent variable\n",
    "# -> used for prediction of continuous numerical values based on input\n",
    "# -> in regression, the given data is fit into mathematical function and relation between variable is found out\n",
    "# -> Process of Regression involves training model on labeled dataset\n",
    "\n",
    "# Some Regression Algorithms\n",
    "#     -> Linear Regression\n",
    "#     -> Polynomial Regression\n",
    "#     -> Ridge Regression and Lasso Regression\n",
    "#     -> Decision Tree Regression\n",
    "#     -> Support Vector Regression\n",
    "#     -> Random Forest Regression\n",
    "#     -> Neural Network Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "#     -> simplest and widely used Regression Model\n",
    "#     -> assumes linear relation between independent and dependent data\n",
    "#     -> seeks to find best fit line that minimizes the difference between predcited and actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "#     -> extends Linear Regression and allows relation between variables to be nth of nth degree\n",
    "#     -> captures non linear relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8308139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression and Lasso Regression\n",
    "#     -> variants of Linear Regression that address the problem of overfitting\n",
    "#     -> add a regularization term to the loss function\n",
    "#     -> prevents over-reliance on individual features and encourages simpler models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8eb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression\n",
    "#     -> uses Decision Tree structure (Binary Tree) to model relationships between variables\n",
    "#     -> breaks data into smaller subsets and predicts the average value of target variable in each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71388d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "#     -> (didnot understood need to write later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "#     -> builds an ensemble (group) of decision trees \n",
    "#     -> combines their predictions to make a final prediction\n",
    "#     -> helps to reduce overfitting and provides more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fcacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Regression\n",
    "#     -> consist of multiple interconnected layers of artificial neurons that can learn complex patterns \n",
    "#     and relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86321479",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2cdf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "#     -> involves categorizing data into predefined classes or categories based on their features\n",
    "#     -> used for tasks such as spam detection, image recognition, sentiment analysis, and fraud detection\n",
    "#     -> the goal is to train a model that can accurately predict the class labels of new, unseen data points\n",
    "#     -> Process of Classification involves training model on labeled dataset\n",
    "\n",
    "# Some Classification Algorithms\n",
    "#     -> Logistic Regression\n",
    "#     -> Naive Bayes\n",
    "#     -> Decision Trees\n",
    "#     -> Random Forest\n",
    "#     -> Support Vector Machines(SVM)\n",
    "#     -> K-Nearest Neighbour (KNN)\n",
    "#     -> Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "#     -> models the relationship between the features and the probability of belonging to a certain class.\n",
    "#     -> uses a logistic function to map the input features to a probability value\n",
    "#     -> makes predictions based on a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "#     -> A probabilistic classifier based on Bayes theorem\n",
    "#     -> particularly useful for text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "#     -> create a tree-like model where each internal node represents a feature or attribute\n",
    "#     -> each branch represents a decision based on that feature, and each leaf node represents a class label\n",
    "#     -> handles both categorical and numerical features and are easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e649171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "#     -> builds an ensemble (group) of decision trees \n",
    "#     -> creates a collection of decision trees\n",
    "#     -> makes predictions by averaging on the predictions of individual trees. \n",
    "#     -> known for their robustness and ability to handle high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24df746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "#     -> (didnot understood need to write later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K-Nearest Neighbors \n",
    "#     -> simple classification algorithm\n",
    "#     -> classifies data points based on their proximity to other labeled data points in the feature space. \n",
    "#     -> class label is determined by the majority vote of the k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f21bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "#     -> Consist of multiple interconnected layers of artificial neurons that can learn complex patterns \n",
    "#                 and relationships in the data\n",
    "#     ->  Deep learning models such as convolutional neural networks (CNNs) \n",
    "#             are particularly effective for image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7ef76",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "#     -> a machine learning technique used for grouping similar objects together based on their inherent property\n",
    "#     -> the goal of clustering is to find patterns in the data withour prior knowledge of groups or categories\n",
    "#     -> it is unsupervised machine learning method\n",
    "#     -> first dataset is anaylzed and objects are grouped into clusters based on their similarity \n",
    "#     -> similarity or dissimilarity between objects is measured using various distance or similarity metrics\n",
    "#     -> some of the metrics are\n",
    "#             -> Euclidean distance \n",
    "#             -> cosine similarity\n",
    "#             -> Inertia or Sum of Squared Errors (SSE)\n",
    "#             -> Silhouette Coefficient\n",
    "#             -> Adjusted Rand Index (ARI)\n",
    "#             -> Davies-Bouldin Index (DBI)\n",
    "#             -> Calinski-Harabasz Index\n",
    "#             -> Normalized Mutual Information (NMI)\n",
    "#     -> choice of distance metric depends on the nature of the data and the clustering algorithm being used.\n",
    "#     -> used for customer segmentation, image recognition, anomaly detection, document classification, and more\n",
    "\n",
    "# Some Popular Clustering Algorithm\n",
    "#     -> K-means\n",
    "#     -> Hierarchical clustering\n",
    "#     -> DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "#     -> Mean Shift\n",
    "#     -> Gaussian Mixture Models (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "#     -> a centroid-based algorithm \n",
    "#     -> data is partitioned into a predefined number of clusters (k)\n",
    "#     -> aims to minimize the sum of squared distances between data points and their assigned cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699fc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering\n",
    "#     -> This approach creates a hierarchy of clusters by successively merging or splitting existing clusters.\n",
    "#     -> It can be agglomerative (bottom-up) or divisive (top-down) in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN \n",
    "#     -> Stands for Density-Based Spatial Clustering of Applications with Noise\n",
    "#     -> groups together data points that are close to each other and separates regions with low data density\n",
    "#     -> effective in handling datasets with irregularly shaped clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15222834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Shift \n",
    "#     -> a non-parametric algorithm that assigns data points to clusters by iteratively shifting the \n",
    "#         centroids based on the density of the data points.\n",
    "#     -> It is capable of finding clusters of varying shapes and sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd159fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Mixture Models\n",
    "#     -> GMM assumes that the data points are generated from a mixture of Gaussian distributions. \n",
    "#     -> It estimates the parameters of these distributions to determine\n",
    "#         the cluster assignments of the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940360ee",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c50bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction\n",
    "#     -> process of reducing the number of variables or features in a dataset\n",
    "#     -> while preserving the essential information.\n",
    "#     -> commonly used in machine learning and data analysis to overcome the curse of dimensionality, \n",
    "#         improve computational efficiency, and enhance visualization.\n",
    "#     -> primary goal of dimensionality reduction is to transform high-dimensional data into a\n",
    "#     -> lower-dimensional representation, while minimizing the loss of information\n",
    "#     -> lower-dimensional representation reduces the complexity of the data, improving model performance, \n",
    "#     -> and gaining insights into the underlying structure of the data.\n",
    "#     -> 2 main approaches: Feature selection and Feature Extraction\n",
    "#     -> Commonly used Dimension Reduction Techniques are :\n",
    "#             -> Principal Component Analysis (PCA)\n",
    "#             -> t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "#             -> Linear Discriminant Analysis (LDA)\n",
    "#             -> Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "#     -> an unsupervised technique that transforms the data into a new coordinate system\n",
    "#     -> here the dimensions (principal components) are orthogonal and capture the maximum variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409fe56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "#     -> a nonlinear technique used for visualization and high-dimensional data exploration\n",
    "#     -> preserves the local structure of the data points\n",
    "#     -> useful for visualizing clusters or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis (LDA)\n",
    "#     -> a supervised dimensionality reduction technique that finds a projection of the data\n",
    "#     -> that maximizes class separability\n",
    "#     -> LDA is often used for classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ba915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoders\n",
    "#     -> They are neural network models that aim to reconstruct the input data from a compressed representation\n",
    "#     -> it can learn an efficient representation of the data\n",
    "#     -> effective for nonlinear dimensionality reduction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
